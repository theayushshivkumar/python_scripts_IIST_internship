{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0741d15-a83f-48d0-99f0-0a83eedcddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\myenv39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\myenv39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\myenv39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.6 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/11.6 MB 4.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/11.6 MB 4.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.0/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.2/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.8/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.0/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.3/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.1/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.6/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.2/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.4/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.5/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.0/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.2/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.4/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.1/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.1/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.6/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 112.6/345.4 kB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 297.0/345.4 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 345.4/345.4 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.0\n",
      "    Uninstalling numpy-1.20.0:\n",
      "      Successfully uninstalled numpy-1.20.0\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\envs\\myenv39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\envs\\myenv39\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\myenv39\\Lib\\site-packages\\numpy\\~libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\myenv39\\Lib\\site-packages\\numpy\\~-re'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\myenv39\\Lib\\site-packages\\numpy\\~-t'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\myenv39\\Lib\\site-packages\\numpy\\~-nalg'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\myenv39\\Lib\\site-packages\\numpy\\~-ndom'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2898fdf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23816\\1341979645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlmfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmfit\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from decimal import Decimal\n",
    "\n",
    "hdul_70to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_UNIMAP_70to500_cutout.fits\")\n",
    "hdul_160to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_UNIMAP_160to500_cutout.fits\")\n",
    "hdul_250to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_250to500_cutout.fits\")\n",
    "hdul_350to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_350to500_cutout.fits\")\n",
    "hdul_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_500_cutout.fits\")\n",
    "hdul_atlas = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_ATLASGAL_870to500_aniano_cutout.fits\")\n",
    "\n",
    "data_70 = hdul_70to500[0].data\n",
    "data_160 = hdul_160to500[0].data\n",
    "data_250 = hdul_250to500[0].data\n",
    "data_350 = hdul_350to500[0].data\n",
    "data_500 = hdul_500[0].data\n",
    "data_atlas = hdul_atlas[0].data\n",
    "\n",
    "header_70 = hdul_70to500[0].header\n",
    "\n",
    "h = 6.626 * 10 ** -34\n",
    "k = 1.38 * 10 ** -23\n",
    "c = 3 * 10 ** 8\n",
    "\n",
    "def BB(freq, Td):\n",
    "    return (2 * h * freq**3)/((c**2) * (np.exp(h * freq / (k * Td)) - 1))\n",
    "\n",
    "def K(freq):\n",
    "    return 0.1 * 0.1 * (freq/(10 ** 12))**2 # Beta is equal to 2 (dust emissivity index), 0.1 multiplied to convert into SI from cgs.\n",
    "\n",
    "def tau(freq, NH):\n",
    "    return ((2.86) * (1.67 * 10**(-27)) * K(freq) * NH) # mean_weight times mass of hydrogen in Kg. \n",
    "\n",
    "def modified_BB(freq,Td, NH):\n",
    "    return (((6.78739347477e-5)**2) * BB(freq, Td) * (1 - np.exp(-1 * tau(freq,NH)))) #Pixel size = 14'' converted to sterradian.\n",
    "\n",
    "#def modified_BB(freq,Td, NH2):\n",
    "    #return (2*h*freq**3/((c**2) * (np.exp(h*freq / (k*Td)) - 1))) * (Td) * (1 - (np.exp(-1 * ((2.86) * (1.67 * 10**(-27)) * (0.1 * (freq/1000)**2) * NH2))))\n",
    "\n",
    "#wavelength = np.array([70, 160, 250, 350, 500, 870]) * (10**(-6))\n",
    "wavelength = np.array([70, 160, 250, 350, 500]) * (10**(-6))\n",
    "#wavelength = wavelength.astype(np.float64)\n",
    "\n",
    "f = c/wavelength\n",
    "\n",
    "BBmodel = lmfit.Model(modified_BB, independent_vars = [\"freq\"])\n",
    "\n",
    "########### BRIGHT PIXELS ##############\n",
    "\n",
    "#1datas = np.array([data_70[100, 54], data_160[100, 54], data_250[100, 54], data_350[100, 54], data_500[100, 54]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#2datas = np.array([data_70[99, 54], data_160[99, 54], data_250[99, 54], data_350[99, 54], data_500[99, 54]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#3 datas = np.array([data_70[100, 55], data_160[100, 55], data_250[100, 55], data_350[100, 55], data_500[100, 55], data_atlas[100, 55]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#4 datas = np.array([data_70[99, 55], data_160[99, 55], data_250[99, 55], data_350[99, 55], data_500[99, 55]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#5 datas = np.array([data_70[100, 53], data_160[100, 53], data_250[100, 53], data_350[100, 53], data_500[100, 53], data_atlas[100, 53]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#6 datas = np.array([data_70[100, 56], data_160[100, 56], data_250[100, 56], data_350[100, 56], data_500[100, 56], data_atlas[100, 56]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#7 datas = np.array([data_70[99, 53], data_160[99, 53], data_250[99, 53], data_350[99, 53], data_500[99, 53], data_atlas[99, 53]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#8 datas = np.array([data_70[101, 54], data_160[101, 54], data_250[101, 54], data_350[101, 54], data_500[101, 54], data_atlas[101, 54]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#9 datas = np.array([data_70[101, 54], data_160[101, 54], data_250[101, 54], data_350[101, 54], data_500[101, 54], data_atlas[101, 54]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "\n",
    "########### DIFFUSE PIXELS #############\n",
    "\n",
    "#1 datas = np.array([data_70[95, 74], data_160[95, 74], data_250[95, 74], data_350[95, 74], data_500[95, 74]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#2 datas = np.array([data_70[90, 74], data_160[90, 74], data_250[90, 74], data_350[90, 74], data_500[90, 74]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#3 datas = np.array([data_70[26, 59], data_160[26, 59], data_250[26, 59], data_350[26, 59], data_500[26, 59]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "datas = np.array([data_70[69, 68], data_160[69, 68], data_250[69, 68], data_350[69, 68], data_500[69, 68]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#5 datas = np.array([data_70[64, 47], data_160[64, 47], data_250[64, 47], data_350[64, 47], data_500[64, 47]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#6 datas = np.array([data_70[62, 43], data_160[62, 43], data_250[62, 43], data_350[62, 43], data_500[62, 43]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "# datas = np.array([data_70[55, 56], data_160[55, 56], data_250[55, 56], data_350[55, 56], data_500[55, 56]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#7 datas = np.array([data_70[95, 67], data_160[95, 67], data_250[95, 67], data_350[95, 67], data_500[95, 67]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#8 datas = np.array([data_70[92, 59], data_160[92, 59], data_250[92, 59], data_350[92, 59], data_500[92, 59]]) * (10 ** (-26))  # 1 Jansky = 10⁻²⁶ watts per square metre per hertz\n",
    "#9 datas = np.array([data_70[138,48], data_160[138, 48], data_250[138, 48], data_350[138, 48], data_500[138, 48]]) * (10 ** (-26))\n",
    "\n",
    "#datas = np.array([data_70[106,130], data_160[106,130], data_250[106,130], data_350[106,130], data_500[106,130]]) * (10 ** (-26)) #BG\n",
    "\n",
    "#datas = np.array([data_70[53,80], data_160[53,80], data_250[53,80], data_350[53,80], data_500[53,80]]) * (10 ** (-26)) #IRDC \n",
    "#datas = np.array([data_70[42,93], data_160[42,93], data_250[42,93], data_350[42,93], data_500[42,93]]) * (10 ** (-26)) #IRDC \n",
    "########### DIFFUSE REGIONS ############\n",
    "\n",
    "#1 datas = np.array([551.85469, 995.86598, 731.72276, 335.59168, 124.36546]) * (10 ** (-26))\n",
    "#2 datas = np.array([260.08455, 630.30437, 597.35953, 284.78876, 107.52943]) * (10 ** (-26))\n",
    "#3 datas = np.array([232.22186, 522.10661, 542.39456, 257.40862, 100.35742]) * (10 ** (-26))\n",
    "#4 datas = np.array([702.84333, 1295.271, 1283.2666, 594.63182, 222.03587]) * (10 ** (-26))\n",
    "#5 datas = np.array([702.84333, 1295.271, 1283.2666, 594.63182, 222.03587]) * (10 ** (-26))\n",
    "#6 datas = np.array([914.43754, 2385.3352, 2178.3858, 1006.3953, 371.80851]) * (10 ** (-26))\n",
    "\n",
    "                                            ########################################\n",
    "\n",
    "# bg_subtraction = np.array([-0.550686, -1.4814, 1.40193, 1.59323, 0.305106, -0.0273185]) * (10 ** (-26))\n",
    "bg_subtraction = np.array([-0.276804, -1.03729, 1.96173, 0.951691, 0.347096]) * (10 ** (-26))\n",
    "# bg_subtraction = np.array([-1.4814, 1.40193, 1.59323, 0.305106]) * (10 ** (-26))\n",
    "\n",
    "subtracted_datas = datas - bg_subtraction\n",
    "\n",
    "wts = 1/(0.15 * subtracted_datas)\n",
    "\n",
    "wavelength_data = np.linspace((10**-6) , (10**-3) , 10000)\n",
    "frequencies_data = np.linspace((10**11) , (10**13) , 10000)\n",
    "\n",
    "params = BBmodel.make_params(Td = 25, NH = 10**26)\n",
    "\n",
    "params['Td'].min = 10\n",
    "params['Td'].max = 40\n",
    "#params['NH'].min = 10**26\n",
    "#params['NH'].max = 10**29\n",
    "\n",
    "\n",
    "print(params)\n",
    "\n",
    "result = BBmodel.fit(subtracted_datas, params, freq = f, weights = wts)\n",
    "\n",
    "parameters = result.params\n",
    "\n",
    "red_chi = result.redchi\n",
    "\n",
    "Td_fit = parameters['Td'].value\n",
    "NH_fit = parameters['NH'].value\n",
    "Td_fit_error = parameters['Td'].stderr\n",
    "NH_fit_error = parameters['NH'].stderr\n",
    "\n",
    "#beta_fit = parameters['beta'].value\n",
    "\n",
    "print(\"\\n\\t\\tPost-Fit Dust Temperature (in Kelvin): %f \\u00B1 %f\" %(Td_fit, Td_fit_error))\n",
    "\n",
    "print(\"\\n\\t\\tPost-Fit Column Density (in /m^2): %e \\u00B1 %e \"%(NH_fit, NH_fit_error))\n",
    "\n",
    "#print(\"\\n\\t\\tDust Emissivity Index (in /m^2): \", beta_fit)\n",
    "print(\"\\n\\t\\tReduced Chi Square: \", red_chi)\n",
    "\n",
    "y = modified_BB(frequencies_data, Td_fit, NH_fit)\n",
    "x = frequencies_data\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "plt.errorbar(f, subtracted_datas/(10**-26), yerr = (0.15 * subtracted_datas/(10**-26)), fmt = 'k.', label = 'observed data points')\n",
    "\n",
    "plt.loglog(x , y/(10**-26), color = 'black', label = 'Diffuse pixel fit') # convert back to Jy/pixel from watts/m^2.Hz\n",
    "\n",
    "#plt.text(1.6 * 10**12, 10**-3, \"Td = %.2f \\u00B1 %.2f K\\n\\n N(H2) = %.2e \\u00B1 %.2e\" %(Td_fit, Td_fit_error, NH_fit, NH_fit_error), fontsize = 14, ha = 'center', va = 'center', color = 'black') #BG\n",
    "plt.text(2 * 10**11, 10**0, \"Td = %.2f \\u00B1 %.2f K\\n\\n N(H2) = %.2e \\u00B1 %.2e /m^2\" %(Td_fit, Td_fit_error, NH_fit, NH_fit_error), fontsize = 13, ha = 'center', va = 'center', color = 'black') #IRDC\n",
    "\n",
    "\n",
    "#plt.plot(f, subtracted_datas/(10**-26),marker = ',', label = 'observed data') # convert back to Jy/pixel\n",
    "\n",
    "plt.xlabel(\"Frequency (Hz)\", fontsize = 15)\n",
    "plt.ylabel(\"Flux Density (Jy/pixel)\", fontsize = 15)\n",
    "plt.title(\"Flux Density v/s Frequency\", fontsize = 15)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\pixelinglol.png\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293b62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.42921304421357737\n",
      "-1.4499784794701454\n",
      "1.7659597415303216\n",
      "0.8623561198142513\n",
      "0.31009662126574794\n",
      "Parameters([('Td', <Parameter 'Td', value=20.0, bounds=[-inf:inf]>), ('NH', <Parameter 'NH', value=1e+25, bounds=[-inf:inf]>)])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmfit\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from decimal import Decimal\n",
    "\n",
    "hdul_70to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_UNIMAP_70to500_cutout.fits\")\n",
    "hdul_160to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_UNIMAP_160to500_cutout.fits\")\n",
    "hdul_250to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_250to500_cutout.fits\")\n",
    "hdul_350to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_350to500_cutout.fits\")\n",
    "hdul_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_25_SPIRE_500_cutout.fits\")\n",
    "hdul_atlas = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\CutoutsLevel25\\level_ATLASGAL_870to500_aniano_cutout.fits\")\n",
    "\n",
    "data_70 = hdul_70to500[0].data\n",
    "data_160 = hdul_160to500[0].data\n",
    "data_250 = hdul_250to500[0].data\n",
    "data_350 = hdul_350to500[0].data\n",
    "data_500 = hdul_500[0].data\n",
    "data_atlas = hdul_atlas[0].data\n",
    "\n",
    "header_70 = hdul_70to500[0].header\n",
    "\n",
    "h = 6.626 * 10 ** -34\n",
    "k = 1.38 * 10 ** -23\n",
    "c = 3 * 10 ** 8\n",
    "\n",
    "def BB(freq, Td):\n",
    "    return (2 * h * freq**3)/((c**2) * (np.exp(h * freq / (k * Td)) - 1))\n",
    "\n",
    "def K(freq):\n",
    "    return 0.1 * 0.1 * (freq/(10 ** 12))**2 # Beta is equal to 2 (dust emissivity index), 0.1 multiplied to convert into SI from cgs.\n",
    "\n",
    "def tau(freq, NH):\n",
    "    return ((2.86) * (1.67 * 10**(-27)) * K(freq) * NH) # mean_weight times mass of hydrogen in Kg. \n",
    "\n",
    "def modified_BB(freq,Td, NH):\n",
    "    return (((6.78739347477e-5)**2) * BB(freq, Td) * (1 - np.exp(-1 * tau(freq,NH)))) #Pixel size = 14'' converted to sterradian.\n",
    "\n",
    "wavelength = np.array([70,160,250,350,500]) * (10**(-6))\n",
    "\n",
    "f = c/wavelength\n",
    "\n",
    "datas = np.array([data_70, data_160, data_250, data_350, data_500, data_atlas]) * (10**(-26))\n",
    "\n",
    "#bg_subtraction = np.array([np.nanmin(data_70), np.nanmin(data_160), np.nanmin(data_250), np.nanmin(data_350), np.nanmin(data_500), np.nanmin(data_atlas)]) * (10 ** (-26))\n",
    "bg_subtraction = np.array([-0.42921304421357737, -1.4499784794701454, 1.7659597415303216, 0.8623561198142513, 0.31009662126574794, -0.3]) * (10 ** (-26))\n",
    "\n",
    "-0.42921304421357737\n",
    "-1.4499784794701454\n",
    "1.7659597415303216\n",
    "0.8623561198142513\n",
    "0.31009662126574794\n",
    "\n",
    "data_70_sub = datas[0] - bg_subtraction[0]\n",
    "data_160_sub = datas[1] - bg_subtraction[1]\n",
    "data_250_sub = datas[2] - bg_subtraction[2]\n",
    "data_350_sub = datas[3] - bg_subtraction[3]\n",
    "data_500_sub = datas[4] - bg_subtraction[4]\n",
    "data_atlas_sub = datas[5] - bg_subtraction[5]\n",
    "\n",
    "datas_sub = np.array([data_70_sub, data_160_sub, data_250_sub, data_350_sub, data_500_sub])\n",
    "\n",
    "print(np.nanmin(data_70))\n",
    "print(np.nanmin(data_160))\n",
    "print(np.nanmin(data_250))\n",
    "print(np.nanmin(data_350))\n",
    "print(np.nanmin(data_500))\n",
    "\n",
    "#print(datas[0])\n",
    "\n",
    "\n",
    "#print(bg_subtraction[0])\n",
    "#print(datas[0,0,0])\n",
    "#print(data_70[0,0])\n",
    "#mask = np.isnan(datas_sub)\n",
    "#masked_datas = np.ma.masked_array(datas_sub, mask)\n",
    "#masked_datas = masked_datas.astype(np.float64)\n",
    "\n",
    "BBmodel_loop = lmfit.Model(modified_BB, independent_vars = [\"freq\"])\n",
    "params = BBmodel_loop.make_params(Td = 20, NH = (10**25)) \n",
    "\n",
    "#params['beta'].min = 1.4\n",
    "#params['beta'].max = 2.6\n",
    "\n",
    "\n",
    "#params['Td'].min = 15\n",
    "#params['Td'].max = 60\n",
    "\n",
    "#params['NH'].min = 10**22\n",
    "\n",
    "print(params)\n",
    "\n",
    "mask = datas_sub == 0\n",
    "\n",
    "datas_sub_mask = np.ma.masked_array(datas_sub, mask)\n",
    "\n",
    "print(datas_sub_mask.any() == 0)\n",
    "\n",
    "wts = 1/(0.15 * datas_sub) \n",
    "\n",
    "#with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#   result = np.divide(1, (0.15 * datas_sub)\n",
    "\n",
    "NH_model = np.zeros((150, 150), dtype = float)\n",
    "Td_model = np.zeros((150, 150), dtype = float)\n",
    "red_chi_square = np.zeros((150, 150), dtype = float)\n",
    "beta_model = np.zeros((150,150), dtype = float)\n",
    "\n",
    "    \n",
    "for i in range(150):\n",
    "        \n",
    "        for j in range(150):\n",
    "           \n",
    "            try:\n",
    "                    #print(i)\n",
    "                    #print(j)\n",
    "\n",
    "                    result =  BBmodel.fit(datas_sub[:,i,j], params, freq = f, weights = wts[:,i,j])    \n",
    "\n",
    "                    parameters = result.params\n",
    "\n",
    "                    red_chi = result.redchi\n",
    "\n",
    "                    red_chi_square[i,j] = red_chi\n",
    "\n",
    "                    Td_fit = parameters['Td'].value\n",
    "                    #print(\"Td : \", Td_fit)\n",
    "                    Td_model[i,j] = Td_fit\n",
    "\n",
    "                    NH_fit = parameters['NH'].value  \n",
    "                    #print(\"NH : \", NH_fit)\n",
    "                    NH_model[i,j] = NH_fit\n",
    "                    \n",
    "                    #beta_fit = parameters['beta'].value  \n",
    "                    #print(\"Dust index : \", beta_fit)\n",
    "                    #beta_model[i,j] = beta_fit\n",
    "                    \n",
    "            except: \n",
    "                pass\n",
    "\n",
    "\n",
    "frequencies_data = np.linspace(10 ** 11 , 10 ** 13 , 150)\n",
    "#result.params.pretty_print()\n",
    "\n",
    "\n",
    "hdu_red_chi = fits.PrimaryHDU(data = red_chi_square, header = header_70)\n",
    "hdul_red_chi = fits.HDUList([hdu_red_chi])\n",
    "hdul_red_chi.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\Fit_Parameters\\lvl2_5_ReducedChi.fits\", overwrite=True)\n",
    "\n",
    "hdu_Td_model = fits.PrimaryHDU(data = Td_model, header = header_70)\n",
    "hdul_Td_model = fits.HDUList([hdu_Td_model])\n",
    "hdul_Td_model.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\Fit_Parameters\\lvl2_5_DustTemperature.fits\", overwrite=True)\n",
    "\n",
    "hdu_NH_model = fits.PrimaryHDU(data = NH_model, header = header_70)\n",
    "hdul_NH_model = fits.HDUList([hdu_NH_model])\n",
    "hdul_NH_model.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\Fit_Parameters\\lvl2_5_ColumnDensity.fits\", overwrite=True)\n",
    "\n",
    "#hdu_beta_model = fits.PrimaryHDU(data = beta_model, header = header_350)\n",
    "#hdul_beta_model = fits.HDUList([hdu_beta_model])\n",
    "#hdul_beta_model.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\LMfit Params\\beta_model.fits\", overwrite=True)\n",
    "\n",
    "#y = modified_BB(frequencies_data, Td_model, NH_model)\n",
    "#x = frequencies_data\n",
    "\n",
    "#plt.errorbar(f, subtracted_datas/(10**-26), yerr = (0.15 * subtracted_datas)/(10**-26))\n",
    "#plt.loglog(x , y/(10**-26), color = 'black', label = 'lmfit model curve') # convert back to Jy/pixel from watts/m^2.Hz\n",
    "\n",
    "#plt.loglog(f, subtracted_datas/(10**-26), color = 'b', label = 'observed data') # convert back to Jy/pixel\n",
    "\n",
    "#x = NH_model\n",
    "#y = tau(frequencies_data,beta_model,NH_model)\n",
    "\n",
    "\n",
    "#plt.scatter(x , y, marker = 'x')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c04eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul_70to500.close()\n",
    "hdul_160to500.close()\n",
    "hdul_250to500.close()\n",
    "hdul_350to500.close()\n",
    "hdul_500.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6563d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
