{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052bc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "hdul_70to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\PACS_UNIMAP_70_convTo_500_aniano.fits\")\n",
    "hdul_160to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\PACS_UNIMAP_160_convTo_500_aniano.fits\")\n",
    "hdul_250to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\250_Hipeunit_1307_convTo_500_aniano.fits\")\n",
    "hdul_350to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\350_Hipeunit_1307_convTo_500_aniano.fits\")\n",
    "hdul_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\500_Hipeunit_1307.fits\")\n",
    "hdul_atlasgal = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\ATLASGAL_unitconv_hiped_header_changed_convTo_500_aniano.fits\")\n",
    "\n",
    "primary_hdu_70 = hdul_70to500[1]\n",
    "primary_hdu_160 = hdul_160to500[1]\n",
    "primary_hdu_250 = hdul_250to500[1]\n",
    "primary_hdu_350 = hdul_350to500[1]\n",
    "primary_hdu_500 = hdul_500[1]\n",
    "primary_hdu_atlasgal = hdul_atlasgal[1]\n",
    "\n",
    "\n",
    "data_70 = primary_hdu_70.data\n",
    "data_160 = primary_hdu_160.data\n",
    "data_250 = primary_hdu_250.data\n",
    "data_350 = primary_hdu_350.data\n",
    "data_500 = primary_hdu_500.data\n",
    "data_atlasgal = primary_hdu_atlasgal.data\n",
    "\n",
    "header_70 = primary_hdu_70.header\n",
    "header_160 = primary_hdu_160.header\n",
    "header_250 = primary_hdu_250.header\n",
    "header_350 = primary_hdu_350.header\n",
    "header_500 = primary_hdu_500.header\n",
    "header_atlasgal = primary_hdu_atlasgal.header\n",
    "\n",
    "# Extracting second Header and writing to separate FITS\n",
    "hdu_70to500_header = fits.PrimaryHDU(data = data_70, header = header_70)\n",
    "hdul_70to500_header = fits.HDUList([hdu_70to500_header])\n",
    "hdul_70to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_UNIMAP_70to500_header.fits\", overwrite = True)\n",
    "\n",
    "hdu_160to500_header = fits.PrimaryHDU(data = data_160, header = header_160)\n",
    "hdul_160to500_header = fits.HDUList([hdu_160to500_header])\n",
    "hdul_160to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_UNIMAP_160to500_header.fits\", overwrite = True)\n",
    "\n",
    "hdu_250to500_header = fits.PrimaryHDU(data = data_250, header = header_250)\n",
    "hdul_250to500_header = fits.HDUList([hdu_250to500_header])\n",
    "hdul_250to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_250to500_header.fits\", overwrite = True)\n",
    "\n",
    "hdu_350to500_header = fits.PrimaryHDU(data = data_350, header = header_350)\n",
    "hdul_350to500_header = fits.HDUList([hdu_350to500_header])\n",
    "hdul_350to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_350to500_header.fits\", overwrite = True)\n",
    "\n",
    "hdu_500_header = fits.PrimaryHDU(data = data_500, header = header_500)\n",
    "hdul_500_header = fits.HDUList([hdu_500_header])\n",
    "hdul_500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_500_header.fits\", overwrite = True)\n",
    "\n",
    "hdu_atlasgal_header = fits.PrimaryHDU(data = data_atlasgal, header = header_atlasgal)\n",
    "hdul_atlasgal_header = fits.HDUList([hdu_atlasgal_header])\n",
    "hdul_atlasgal_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL 2_5 Everything 13072003\\convolved\\HeaderExtracted\\Level_25_ATLASGAL_header_aniano.fits\", overwrite = True)\n",
    "\n",
    "hdul_70to500.close()\n",
    "hdul_160to500.close()\n",
    "hdul_250to500.close()\n",
    "hdul_350to500.close()\n",
    "hdul_500.close()\n",
    "hdul_atlasgal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aeebec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul_70to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\PACS_UNIMAP_70to500_header.fits\")\n",
    "hdul_160to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\PACS_UNIMAP_160to500_header.fits\")\n",
    "hdul_250to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\SPIRE_level2_250to500_header.fits\")\n",
    "hdul_350to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\SPIRE_level2_350to500_header.fits\")\n",
    "hdul_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\SPIRE_level2_500_header.fits\")\n",
    "\n",
    "\n",
    "primary_hdu_70 = hdul_70to500[0]\n",
    "primary_hdu_160 = hdul_160to500[0]\n",
    "primary_hdu_250 = hdul_250to500[0]\n",
    "primary_hdu_350 = hdul_350to500[0]\n",
    "primary_hdu_500 = hdul_500[0]\n",
    "\n",
    "data_70 = primary_hdu_70.data\n",
    "data_160 = primary_hdu_160.data\n",
    "data_250 = primary_hdu_250.data\n",
    "data_350 = primary_hdu_350.data\n",
    "data_500 = primary_hdu_500.data\n",
    "\n",
    "header_70 = primary_hdu_70.header\n",
    "header_160 = primary_hdu_160.header\n",
    "header_250 = primary_hdu_250.header\n",
    "header_350 = primary_hdu_350.header\n",
    "header_500 = primary_hdu_500.header\n",
    "\n",
    "#header_70names = header_70.keys()\n",
    "#header_160names = header_160.keys()\n",
    "#header_250names = header_250.keys()\n",
    "#header_350names = header_350.keys()\n",
    "#header_500names = header_500.keys()\n",
    "\n",
    "############################################################\n",
    "\n",
    "flux_unit_250 = header_250[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_250 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_250 = data_250 * conv_factor\n",
    "    \n",
    "    header_250['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_250to500_conv = fits.PrimaryHDU(data = data_250, header = header_250)\n",
    "    \n",
    "    hdul_250to500_conv = fits.HDUList([hdu_250to500_conv])\n",
    "    \n",
    "    hdul_250to500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\unitconvertedLEVEL2\\LEVEL2_250to500_unitconv.fits\", overwrite = True)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "flux_unit_350 = header_350[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_350 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_350 = data_350 * conv_factor\n",
    "    \n",
    "    header_350['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_350to500_conv = fits.PrimaryHDU(data = data_350, header = header_350)\n",
    "    \n",
    "    hdul_350to500_conv = fits.HDUList([hdu_350to500_conv])\n",
    "\n",
    "    hdul_350to500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\unitconvertedLEVEL2\\LEVEL2_350to500_unitconv.fits\", overwrite = True)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "flux_unit_500 = header_500[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_500 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_500 = data_500 * conv_factor\n",
    "    \n",
    "    header_500['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_500_conv = fits.PrimaryHDU(data = data_500, header = header_500)\n",
    "    \n",
    "    hdul_500_conv = fits.HDUList([hdu_500_conv])\n",
    "    \n",
    "    hdul_500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\LEVEL2 + APEX-PLANCK\\Level 2 convolved\\unitconvertedLEVEL2\\LEVEL2_500_unitconv.fits\", overwrite = True)\n",
    "\n",
    "############################################################\n",
    "\n",
    "hdul_250to500.close()\n",
    "hdul_350to500.close()\n",
    "hdul_500.close()\n",
    "hdul_160to500.close()\n",
    "hdul_70to500.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c7b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<astropy.io.fits.hdu.image.PrimaryHDU object at 0x000002797DC45BA0>, <astropy.io.fits.hdu.image.ImageHDU object at 0x000002797DC45570>]\n",
      "[<astropy.io.fits.hdu.image.PrimaryHDU object at 0x000002797DD37760>, <astropy.io.fits.hdu.image.ImageHDU object at 0x000002797DC45240>]\n"
     ]
    }
   ],
   "source": [
    "#NEW fits!!!!!\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "hdul_70 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\Downloads\\PACS_UNIMAP_70.fits\")\n",
    "hdul_160 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\Downloads\\PACS_UNIMAP_160.fits\")\n",
    "hdul_250 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\Downloads\\hspire_newmaps\\hspire250_30pxmp_1827_m1134_1476890437303.fits\")\n",
    "hdul_350 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\Downloads\\hspire_newmaps\\hspire350_30pxmp_1827_m1134_1476890419746.fits\")\n",
    "hdul_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\Downloads\\hspire_newmaps\\hspire500_30pxmp_1827_m1134_1476890410609 (1).fits\")\n",
    "\n",
    "#hdu_70 = hdul_70to500[1]\n",
    "#hdu_160 = hdul_160to500[1]\n",
    "#hdu_250 = hdul_250to500[1]\n",
    "#hdu_350 = hdul_350to500[1]\n",
    "#hdu_500 = hdul_500[1]\n",
    "\n",
    "data_70 = [hdul_70[0].data, hdul_70[1].data]\n",
    "data_160 = [hdul_160[0].data, hdul_160[1].data]\n",
    "data_250 = [hdul_250[0].data, hdul_250[1].data]\n",
    "data_350 = [hdul_350[0].data, hdul_350[1].data]\n",
    "data_500 = [hdul_500[0].data, hdul_500[1].data]\n",
    "\n",
    "header_70 = [hdul_70[0].header, hdul_70[1].header]\n",
    "header_160 = [hdul_160[0].header, hdul_160[1].header]\n",
    "header_250 = [hdul_250[0].header, hdul_250[1].header]\n",
    "header_350 = [hdul_350[0].header, hdul_350[1].header]\n",
    "header_500 = [hdul_500[0].header, hdul_500[1].header]\n",
    "\n",
    "# Extracting second Header and writing to separate FITS\n",
    "#hdu_70to500_header = fits.PrimaryHDU(data = data_70, header = header_70)\n",
    "#hdul_70to500_header = fits.HDUList([hdu_70to500_header])\n",
    "#hdul_70to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\PACS_70_headers.fits\", overwrite = True)\n",
    "\n",
    "new_hdul_70 = fits.HDUList([fits.PrimaryHDU(header = header_70[0], data = data_70[0]), fits.ImageHDU(header = header_70[1], data = data_70[1])])\n",
    "\n",
    "new_hdul_70.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\PACS_70_headers.fits\", overwrite = True)\n",
    "\n",
    "######\n",
    "\n",
    "new_hdul_160 = fits.HDUList([fits.PrimaryHDU(header = header_160[0], data = data_160[0]), fits.ImageHDU(header = header_160[1], data = data_160[1])])\n",
    "\n",
    "new_hdul_160.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\PACS_160_headers.fits\", overwrite = True)\n",
    "\n",
    "######\n",
    "\n",
    "new_hdul_250 = fits.HDUList([fits.PrimaryHDU(header = header_250[0], data = data_250[0]), fits.ImageHDU(header = header_250[1], data = data_250[1])])\n",
    "\n",
    "new_hdul_250.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\SPIRE_250_headers.fits\", overwrite = True)\n",
    "\n",
    "######\n",
    "\n",
    "new_hdul_350 = fits.HDUList([fits.PrimaryHDU(header = header_350[0], data = data_350[0]), fits.ImageHDU(header = header_350[1], data = data_350[1])])\n",
    "\n",
    "new_hdul_350.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\SPIRE_350_headers.fits\", overwrite = True)\n",
    "\n",
    "######\n",
    "\n",
    "new_hdul_500 = fits.HDUList([fits.PrimaryHDU(header = header_500[0], data = data_500[0]), fits.ImageHDU(header = header_500[1], data = data_500[1])])\n",
    "\n",
    "new_hdul_500.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\Extracted Header FITS\\SPIRE_500_headers.fits\", overwrite = True)\n",
    "\n",
    "print(new_hdul_70)\n",
    "print(new_hdul_250)\n",
    "hdul_70.close()\n",
    "hdul_160.close()\n",
    "hdul_250.close()\n",
    "hdul_350.close()\n",
    "hdul_500.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d42dd874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HDUList.close of [<astropy.io.fits.hdu.image.PrimaryHDU object at 0x000002797EC8A1D0>, <astropy.io.fits.hdu.image.ImageHDU object at 0x000002797F1E9060>]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_250 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\SPIRE_250_header_convTo_500_aniano.fits\")\n",
    "file_350 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\SPIRE_350_header_convTo_500_aniano.fits\")\n",
    "file_500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\SPIRE_500_headers.fits\")\n",
    "\n",
    "header_250 = file_250[1].header\n",
    "header_350 = file_350[1].header\n",
    "header_500 = file_500[1].header\n",
    "\n",
    "\n",
    "data_250 = file_250[1].data\n",
    "data_350 = file_350[1].data\n",
    "data_500 = file_500[1].data\n",
    "\n",
    "flux_unit_250 = header_250[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_250 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_250 = data_250 * conv_factor\n",
    "    \n",
    "    header_250['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_250to500_conv = fits.PrimaryHDU(data = data_250, header = header_250)\n",
    "    \n",
    "    hdul_250to500_conv = fits.HDUList([hdu_250to500_conv])\n",
    "\n",
    "    hdul_250to500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\250_to_500_unitconv_NEW.fits\", overwrite = True)\n",
    "\n",
    "    \n",
    "flux_unit_350 = header_350[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_350 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_350 = data_350 * conv_factor\n",
    "    \n",
    "    header_350['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_350to500_conv = fits.PrimaryHDU(data = data_350, header = header_350)\n",
    "    \n",
    "    hdul_350to500_conv = fits.HDUList([hdu_350to500_conv])\n",
    "\n",
    "    hdul_350to500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\350_to_500_unitconv_NEW.fits\", overwrite = True)\n",
    "    \n",
    "    \n",
    "flux_unit_500 = header_500[\"BUNIT\"]\n",
    "\n",
    "if flux_unit_500 == 'MJy/sr':\n",
    "    \n",
    "    conv_factor = 0.00460658  # MJy/sr = 0.0046 Jy/pixel\n",
    "    \n",
    "    data_500 = data_500 * conv_factor\n",
    "    \n",
    "    header_500['BUNIT'] = 'Jy/pixel'\n",
    "    \n",
    "    hdu_500_conv = fits.PrimaryHDU(data = data_500, header = header_500)\n",
    "    \n",
    "    hdul_500_conv = fits.HDUList([hdu_500_conv])\n",
    "\n",
    "    hdul_500_conv.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\500_unitconv_NEW.fits\", overwrite = True)\n",
    "\n",
    "file_250.close()\n",
    "file_350.close()\n",
    "file_500.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d177f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "hipe_250to500 = fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\SPIRE_250to500_HIPEunit.fits\")\n",
    "hipe_350to500 =  fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\SPIRE_350to500_HIPEunit.fits\")\n",
    "hipe_500 =  fits.open(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\SPIRE_500_HIPEunit.fits\")\n",
    "\n",
    "hdu_250 = hipe_250to500[1]\n",
    "hdu_350 = hipe_350to500[1]\n",
    "hdu_500 = hipe_500[1]\n",
    "\n",
    "\n",
    "data_250 = hdu_250.data\n",
    "data_350 = hdu_350.data\n",
    "data_500 = hdu_500.data\n",
    "\n",
    "header_250 = hdu_250.header\n",
    "header_350 = hdu_350.header\n",
    "header_500 = hdu_500.header\n",
    "\n",
    "\n",
    "hipe_250to500_header = fits.PrimaryHDU(data = data_250, header = header_250)\n",
    "hipe_250to500_header = fits.HDUList([hipe_250to500_header])\n",
    "hipe_250to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\header_250to500_HIPEunit.fits\", overwrite = True)\n",
    "\n",
    "\n",
    "hipe_350to500_header = fits.PrimaryHDU(data = data_350, header = header_350)\n",
    "hipe_350to500_header = fits.HDUList([hipe_350to500_header])\n",
    "hipe_350to500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\header_350to500_HIPEunit.fits\", overwrite = True)\n",
    "\n",
    "hipe_500_header = fits.PrimaryHDU(data = data_500, header = header_500)\n",
    "hipe_500_header = fits.HDUList([hipe_500_header])\n",
    "hipe_500_header.writeto(r\"C:\\Users\\Ayush Shivkumar\\OneDrive\\Desktop\\IIST\\Books & Material\\Convolved+Regridded FITS\\NEW CONV FITS\\Unit converted USING HIPE\\header_500_HIPEunit.fits\", overwrite = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
